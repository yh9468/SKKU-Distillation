{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def KLDivergenceLoss(y, teacher_scores, mask=None, T=1):\n",
    "    if mask is not None:\n",
    "        if mask.sum() > 0:\n",
    "            p = F.log_softmax(y/T, dim=1)[mask]\n",
    "            q = F.softmax(teacher_scores/T, dim=1)[mask]\n",
    "            l_kl = F.kl_div(p, q, reduce=False)\n",
    "            loss = torch.sum(l_kl)\n",
    "            loss = loss / mask.sum()\n",
    "        else:\n",
    "            loss = torch.Tensor([0]).cuda()\n",
    "    else:\n",
    "        p = F.log_softmax(y/T, dim=1)\n",
    "        q = F.softmax(teacher_scores/T, dim=1)\n",
    "        l_kl = F.kl_div(p, q, reduction='none')\n",
    "        print(l_kl.shape)\n",
    "        loss = l_kl.sum() / l_kl.size(0)\n",
    "    return loss * T**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3103, 0.4623, 0.1610, 0.3564, 0.5454, 0.4771, 0.7310, 0.5640],\n",
      "          [0.5201, 0.5245, 0.4679, 0.4345, 0.6221, 0.5131, 0.5908, 0.8268],\n",
      "          [0.5484, 0.3887, 0.7643, 0.9465, 0.4884, 0.3513, 0.0827, 0.3276],\n",
      "          [0.0913, 0.4069, 0.4183, 0.3688, 0.5249, 0.4338, 0.6115, 0.8638],\n",
      "          [0.3832, 0.4208, 0.5629, 0.2681, 0.5465, 0.2758, 0.4998, 0.4156],\n",
      "          [0.7065, 0.3980, 0.7760, 0.7756, 0.5095, 0.5294, 0.6472, 0.8554],\n",
      "          [0.2101, 0.3683, 0.2958, 0.7957, 0.3317, 0.5470, 0.5953, 0.1993],\n",
      "          [0.2615, 0.2292, 0.3258, 0.5133, 0.4157, 0.6333, 0.1879, 0.2985]]],\n",
      "\n",
      "\n",
      "        [[[0.5245, 0.4307, 0.3246, 0.2587, 0.0689, 0.4002, 0.4409, 0.5081],\n",
      "          [0.7052, 0.3613, 0.8616, 0.6399, 0.2555, 0.3176, 0.3201, 0.3381],\n",
      "          [0.9248, 0.5196, 0.6094, 0.6502, 0.6335, 0.4729, 0.1311, 0.5937],\n",
      "          [0.4982, 0.6021, 0.6952, 0.1020, 0.2954, 0.7950, 0.3156, 0.6178],\n",
      "          [0.5420, 0.5036, 0.7801, 0.5442, 0.2943, 0.4471, 0.8083, 0.7712],\n",
      "          [0.4523, 0.3950, 0.4797, 0.5300, 0.6810, 0.1889, 0.3192, 0.2980],\n",
      "          [0.2555, 0.7316, 0.8725, 0.3246, 0.2384, 0.5423, 0.1193, 0.6899],\n",
      "          [0.7412, 0.3386, 0.5494, 0.3355, 0.4014, 0.7550, 0.0695, 0.3015]]],\n",
      "\n",
      "\n",
      "        [[[0.2339, 0.3470, 0.0628, 0.6668, 0.3208, 0.6284, 0.8308, 0.4921],\n",
      "          [0.7641, 0.7001, 0.2889, 0.4231, 0.5158, 0.5139, 0.2735, 0.1832],\n",
      "          [0.9427, 0.3766, 0.6291, 0.3725, 0.7184, 0.3066, 0.7067, 0.5781],\n",
      "          [0.3638, 0.4783, 0.5709, 0.7053, 0.3494, 0.7152, 0.3164, 0.3357],\n",
      "          [0.2960, 0.4711, 0.3497, 0.2824, 0.8367, 0.6015, 0.2828, 0.8104],\n",
      "          [0.6821, 0.8397, 0.5528, 0.7031, 0.5198, 0.2851, 0.3989, 0.5883],\n",
      "          [0.2892, 0.7320, 0.2131, 0.4095, 0.6694, 0.8756, 0.5486, 0.8895],\n",
      "          [0.7745, 0.5254, 0.4048, 0.6074, 0.4604, 0.7072, 0.5209, 0.6209]]],\n",
      "\n",
      "\n",
      "        [[[0.6275, 0.2528, 0.8972, 0.4098, 0.3208, 0.3283, 0.4976, 0.7253],\n",
      "          [0.3489, 0.3024, 0.6516, 0.6105, 0.2499, 0.6040, 0.6377, 0.7021],\n",
      "          [0.2211, 0.7137, 0.6655, 0.5248, 0.3488, 0.5280, 0.7423, 0.5882],\n",
      "          [0.8039, 0.7233, 0.5123, 0.4681, 0.7103, 0.1141, 0.6120, 0.4722],\n",
      "          [0.3846, 0.2288, 0.4775, 0.7855, 0.6727, 0.4558, 0.5348, 0.5087],\n",
      "          [0.7037, 0.1316, 0.5292, 0.3956, 0.1922, 0.2458, 0.2586, 0.2840],\n",
      "          [0.4126, 0.3821, 0.5803, 0.6000, 0.3096, 0.2507, 0.1707, 0.2345],\n",
      "          [0.6856, 0.2783, 0.8935, 0.7326, 0.1919, 0.5862, 0.3114, 0.5919]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8090)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((4,1, 8, 8))\n",
    "b = torch.randn((4,1, 8, 8)).sigmoid()\n",
    "print(b)\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "loss(a,b)\n",
    "#KLDivergenceLoss(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 8])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[...,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e4a47e36f0811c316f759d1a92830bb55dbd78977c69f453a1e4981941b515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
